{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b350e50",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99949db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the emnist_train.pkl file\n",
    "with open('emnist_train.pkl', 'rb') as f:\n",
    "    train_dict = pickle.load(f, encoding='bytes')\n",
    "\n",
    "# Extract the data and labels arrays from the dictionary\n",
    "train_data = train_dict['data']\n",
    "train_labels = train_dict['labels']\n",
    "\n",
    "\n",
    "# Load the emnist_test.pkl file\n",
    "with open('emnist_test.pkl', 'rb') as f:\n",
    "    test_dict = pickle.load(f, encoding='bytes')\n",
    "    \n",
    "# Extract the data and labels arrays from the dictionary\n",
    "test_data = test_dict['data']\n",
    "test_labels = test_dict['labels']\n",
    "\n",
    "# Convert the data and labels arrays to NumPy arrays\n",
    "train_data = np.array(train_data, dtype=np.float32)\n",
    "train_labels = np.array(train_labels, dtype=np.int32)\n",
    "test_data = np.array(test_data, dtype=np.float32)\n",
    "test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "# Define class names\n",
    "# Create class names for all 62 classes\n",
    "class_names = ['Class {}'.format(i) for i in range(62)] \n",
    "#Plot a grid of EMNIST examples of a specified size.\"\"\"\n",
    "\n",
    "def plot_examples(data, pred, target, n_rows=5, n_cols=5):\n",
    "    \"\"\"Plot a grid of EMNIST examples of a specified size.\"\"\"\n",
    "    # Size figure depending on the size of the grid\n",
    "    plt.figure(figsize=(n_cols * 1.2, n_rows * 2.0))\n",
    "    \n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            # Get the next index of the image\n",
    "            index = n_cols * row + col\n",
    "            \n",
    "            # Reshape the flattened image to its original shape\n",
    "            image = data[index].reshape((28, 28))\n",
    "            \n",
    "            # Plot the image at the appropriate place in the grid\n",
    "            plt.subplot(n_rows, n_cols, index + 1)\n",
    "            plt.imshow(image, cmap=\"binary\")\n",
    "            plt.axis('off')\n",
    "            plt.title(class_names[target[index]] + '\\n' + '>>' + class_names[pred[index]])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot examples from different classes\n",
    "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(class_names):\n",
    "        class_index = i  # Compute the class index\n",
    "        # Get samples of the current class\n",
    "        class_samples = train_data[train_labels == class_index]\n",
    "        # Randomly select a sample from the class\n",
    "        sample_index = np.random.randint(class_samples.shape[0])  \n",
    "        ax.imshow(class_samples[sample_index].reshape((28, 28)), cmap='gray')\n",
    "        ax.axis('off')\n",
    "        # Set the title as the class name\n",
    "        ax.set_title(class_names[class_index])  \n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7f6fd",
   "metadata": {},
   "source": [
    "# MLP without Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ca959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Reshape the data to 2D for MLP\n",
    "train_data = train_data.reshape((-1, 28*28))\n",
    "test_data = test_data.reshape((-1, 28*28))\n",
    "\n",
    "# Normalize the data\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create the MLP model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(28*28,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(train_labels[0]), activation='softmax')  # Number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "train_time = end_time - start_time\n",
    "print('Training time:', train_time)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(test_data)\n",
    "preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Convert back to integer format\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_results = classification_report(test_labels_int, preds_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_results)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "confusion_matrix_results = confusion_matrix(test_labels_int, preds_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_results)\n",
    "\n",
    "accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8e430",
   "metadata": {},
   "source": [
    "# MLP with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a096be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Define the model building function required for KerasClassifier\n",
    "def create_model(n_hidden_layers=2, n_hidden_neurons=50, activation_function='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28*28,)))\n",
    "    for _ in range(n_hidden_layers):\n",
    "        model.add(Dense(n_hidden_neurons, activation=activation_function))\n",
    "    model.add(Dense(len(train_labels[0]), activation='softmax'))  # Number of output classes\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate KerasClassifier with the new model\n",
    "keras_classifier = KerasClassifier(build_fn=create_model, epochs=10, batch_size=128, verbose=0)\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"n_hidden_neurons\": [50, 100, 200],\n",
    "    \"activation_function\": [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid = GridSearchCV(estimator=keras_classifier, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Perform hyperparameter tuning / model selection\n",
    "grid_result = grid.fit(train_data, train_labels)\n",
    "\n",
    "# Print the best score and best parameters\n",
    "print(grid_result.best_score_, grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797aefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = grid_result.best_estimator_.model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "preds = grid_result.best_estimator_.model.predict(test_data)\n",
    "preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Convert back to integer format\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_results = classification_report(test_labels_int, preds_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_results)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "confusion_matrix_results = confusion_matrix(test_labels_int, preds_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_results)\n",
    "\n",
    "accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38c8e0",
   "metadata": {},
   "source": [
    "# MLP Experiments with varying n_hidden_neurons_values and activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db20aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary n_hidden_neurons_values 10 trials with activation_function='relu'\n",
    "n_hidden_neurons_values = np.linspace(50, 200, num=10, dtype=int)\n",
    "n_iterations = 1 \n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_hidden_neurons in n_hidden_neurons_values:\n",
    "    for i in range(n_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = create_model(n_hidden_neurons=n_hidden_neurons, activation_function='relu')\n",
    "        history = model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1, verbose=0)\n",
    "\n",
    "        # Generate predictions\n",
    "        preds = model.predict(test_data)\n",
    "        preds_classes = np.argmax(preds, axis=1)\n",
    "        \n",
    "        # Convert back to integer format\n",
    "        test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "        precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "        recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'Iteration {i+1}, n_hidden_neurons: {n_hidden_neurons}')\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('Precision:', precision)\n",
    "        print('Recall:', recall)\n",
    "        print('Elapsed time:', elapsed_time, 'seconds')\n",
    "\n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_params = {'n_hidden_neurons': n_hidden_neurons}\n",
    "\n",
    "print('Best parameters:', best_params, 'with highest accuracy:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a55afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary n_hidden_neurons_values 10 trials with activation_function='sigmoid'\n",
    "n_hidden_neurons_values = np.linspace(50, 200, num=10, dtype=int)\n",
    "n_iterations = 1 \n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_hidden_neurons in n_hidden_neurons_values:\n",
    "    for i in range(n_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = create_model(n_hidden_neurons=n_hidden_neurons, activation_function='sigmoid')\n",
    "        history = model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1, verbose=0)\n",
    "\n",
    "        # Generate predictions\n",
    "        preds = model.predict(test_data)\n",
    "        preds_classes = np.argmax(preds, axis=1)\n",
    "        \n",
    "        # Convert back to integer format\n",
    "        test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "        precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "        recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'Iteration {i+1}, n_hidden_neurons: {n_hidden_neurons}')\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('Precision:', precision)\n",
    "        print('Recall:', recall)\n",
    "        print('Elapsed time:', elapsed_time, 'seconds')\n",
    "\n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_params = {'n_hidden_neurons': n_hidden_neurons}\n",
    "\n",
    "print('Best parameters:', best_params, 'with highest accuracy:', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vary n_hidden_neurons_values 10 trials with activation_function='tanh'\n",
    "n_hidden_neurons_values = np.linspace(50, 200, num=10, dtype=int)\n",
    "n_iterations = 1 \n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_hidden_neurons in n_hidden_neurons_values:\n",
    "    for i in range(n_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = create_model(n_hidden_neurons=n_hidden_neurons, activation_function='tanh')\n",
    "        history = model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1, verbose=0)\n",
    "\n",
    "        # Generate predictions\n",
    "        preds = model.predict(test_data)\n",
    "        preds_classes = np.argmax(preds, axis=1)\n",
    "        \n",
    "        # Convert back to integer format\n",
    "        test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "        precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "        recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'Iteration {i+1}, n_hidden_neurons: {n_hidden_neurons}')\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('Precision:', precision)\n",
    "        print('Recall:', recall)\n",
    "        print('Elapsed time:', elapsed_time, 'seconds')\n",
    "\n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_params = {'n_hidden_neurons': n_hidden_neurons}\n",
    "\n",
    "print('Best parameters:', best_params, 'with highest accuracy:', best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a4481",
   "metadata": {},
   "source": [
    "# CNN before tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee39e6",
   "metadata": {},
   "source": [
    "rerun the first block and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea62e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_data = train_data.reshape((-1, 28, 28, 1))\n",
    "test_data = test_data.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Normalize the data\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(train_labels[0]), activation='softmax')  # Number of output classes\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "train_time = end_time - start_time\n",
    "print('Training time:', train_time)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(test_data)\n",
    "preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Convert back to integer format\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_results = classification_report(test_labels_int, preds_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_results)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "confusion_matrix_results = confusion_matrix(test_labels_int, preds_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_results)\n",
    "\n",
    "accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a0b4d",
   "metadata": {},
   "source": [
    "# CNN with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f03cee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image \n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    ")\n",
    "datagen.fit(train_data)\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),  # Dropout regularization\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),  # Dropout regularization\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Dropout regularization\n",
    "    Dense(len(train_labels[0]), activation='softmax')  # Number of output classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(datagen.flow(train_data, train_labels, batch_size=128), epochs=10, validation_data=(test_data, test_labels))\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "train_time = end_time - start_time\n",
    "print('Training time:', train_time)\n",
    "\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(test_data)\n",
    "preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Convert back to integer format\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_results = classification_report(test_labels_int, preds_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_results)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "confusion_matrix_results = confusion_matrix(test_labels_int, preds_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_results)\n",
    "\n",
    "accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263e5a1",
   "metadata": {},
   "source": [
    "# Added more Dropout layers and BatchNormalization layers, EarlyStopping callback, and narrowed the search range of learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d140948",
   "metadata": {},
   "source": [
    "rerun the first block and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52806f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Assuming train_data, test_data, train_labels, and test_labels are defined\n",
    "\n",
    "# Reshape and normalize the data\n",
    "train_data = train_data.reshape((-1, 28, 28, 1)) / 255.0\n",
    "test_data = test_data.reshape((-1, 28, 28, 1)) / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(len(train_labels[0]), activation='softmax')  # Number of output classes\n",
    "])\n",
    "\n",
    "# Set learning rate range\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the training time\n",
    "train_time = end_time - start_time\n",
    "print('Training time:', train_time)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(test_data)\n",
    "preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Convert back to integer format\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_results = classification_report(test_labels_int, preds_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_results)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "confusion_matrix_results = confusion_matrix(test_labels_int, preds_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_results)\n",
    "\n",
    "accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "precision = precision_score(test_labels_int, preds_classes, average='macro')\n",
    "recall = recall_score(test_labels_int, preds_classes, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517cede8",
   "metadata": {},
   "source": [
    "# CNN with tuning and solve zero_division"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c806b8b",
   "metadata": {},
   "source": [
    "rerun the first block and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f2774",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Import Keras Tuner related functions\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "hyperparameters = HyperParameters()\n",
    "hyperparameters.Int('conv_1_filters', 32, 128, step=32)\n",
    "hyperparameters.Float('dropout_1', 0.2, 0.5, step=0.1)\n",
    "hyperparameters.Int('conv_2_filters', 64, 256, step=32)\n",
    "hyperparameters.Float('dropout_2', 0.2, 0.5, step=0.1)\n",
    "hyperparameters.Int('dense_units', 128, 512, step=64)\n",
    "hyperparameters.Float('dropout_3', 0.2, 0.5, step=0.1)\n",
    "hyperparameters.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "# Reshape and normalize the data\n",
    "train_data = train_data.reshape((-1, 28, 28, 1)) / 255.0\n",
    "test_data = test_data.reshape((-1, 28, 28, 1)) / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Define the function to build the model\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(hp.Int('conv_1_filters', 32, 128, step=32), (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Conv2D(hp.Int('conv_2_filters', 64, 256, step=32), (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_2', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(hp.Int('dense_units', 128, 512, step=64), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_3', 0.2, 0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(len(train_labels[0]), activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='my_model'\n",
    ")\n",
    "\n",
    "# Create callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(train_data, train_labels, epochs=10, validation_split=0.1, \n",
    "             callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps)\n",
    "\n",
    "# Build the model with the best hyperparameters\n",
    "model = build_model(best_hps)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1, \n",
    "          callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Generate predictions\n",
    "preds = model.predict(test_data)\n",
    "preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "# Convert back to integer format\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Generate and print the classification report\n",
    "classification_report_results = classification_report(test_labels_int, preds_classes, zero_division=1.0)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_results)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "confusion_matrix_results = confusion_matrix(test_labels_int, preds_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_results)\n",
    "\n",
    "# Calculate and print the accuracy, precision, and recall scores\n",
    "accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "precision = precision_score(test_labels_int, preds_classes, average='macro', zero_division=1.0)\n",
    "recall = recall_score(test_labels_int, preds_classes, average='macro', zero_division=1.0)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45862ac",
   "metadata": {},
   "source": [
    "# CNN Experiments with varying learning_rates and dense_units_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ed2fd",
   "metadata": {},
   "source": [
    "rerun the first block and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Assuming train_data, test_data, train_labels, and test_labels are defined\n",
    "\n",
    "# Reshape and normalize the data\n",
    "train_data = train_data.reshape((-1, 28, 28, 1)) / 255.0\n",
    "test_data = test_data.reshape((-1, 28, 28, 1)) / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Define the function to build the model\n",
    "def build_model(units, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(len(train_labels[0]), activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the parameter grid\n",
    "dense_units_options = list(range(128, 512 + 1, 128))  # 10 values from 128 to 512\n",
    "learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]  # 4 values for learning rate\n",
    "\n",
    "# Create callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "\n",
    "# Record results\n",
    "results = []\n",
    "\n",
    "# Perform manual hyperparameter tuning\n",
    "for units in dense_units_options:\n",
    "    for learning_rate in learning_rates:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = build_model(units, learning_rate)\n",
    "\n",
    "        model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.1, \n",
    "                  callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Generate predictions\n",
    "        preds = model.predict(test_data)\n",
    "        preds_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "        # Convert back to integer format\n",
    "        test_labels_int = np.argmax(test_labels, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(test_labels_int, preds_classes)\n",
    "        precision = precision_score(test_labels_int, preds_classes, average='macro', zero_division=1.0)\n",
    "        recall = recall_score(test_labels_int, preds_classes, average='macro', zero_division=1.0)\n",
    "\n",
    "        results.append({\n",
    "            'learning_rate': learning_rate,\n",
    "            'units': units,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'runtime': end_time - start_time\n",
    "        })\n",
    "\n",
    "        print(\"Learning rate:\", learning_rate)\n",
    "        print(\"Units:\", units)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"Runtime:\", end_time - start_time)\n",
    "        print()\n",
    "\n",
    "# Print final results\n",
    "for result in results:\n",
    "    print(\"Learning rate:\", result['learning_rate'])\n",
    "    print(\"Units:\", result['units'])\n",
    "    print(\"Accuracy:\", result['accuracy'])\n",
    "    print(\"Precision:\", result['precision'])\n",
    "    print(\"Recall:\", result['recall'])\n",
    "    print(\"Runtime:\", result['runtime'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaac9c5",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef1463",
   "metadata": {},
   "source": [
    "rerun the first block and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "# Normalise and reshape data\n",
    "train_images = train_data / 255.0\n",
    "test_images = test_data / 255.0\n",
    "\n",
    "# Reshape the data from (28, 28) to (784,)\n",
    "train_images = train_data.reshape(-1, 784)\n",
    "test_images = test_data.reshape(-1, 784)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "train_images = scaler.fit_transform(train_images)\n",
    "test_images = scaler.transform(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the linear SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "start = time.time()\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Print the evaluation metrics and confusion matrix\n",
    "print(\"Accuracy_Linear:\", accuracy)\n",
    "print(\"Precision_Linear:\", precision)\n",
    "print(\"Recall_Linear:\", recall)\n",
    "print(\"Confusion Matrix_Linear:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6bbebe",
   "metadata": {},
   "source": [
    "# PCA compression on Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply PCA without reducing dimensionality, then compute the min number of dimensions for preserving 95% variance\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "\n",
    "pca = PCA(n_components=d)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Transform the test set\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Fit the SVM model on the transformed training set\n",
    "svm_model = SVC(kernel= 'linear')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Make predictions on the transformed test set\n",
    "predictions_pca = svm_model.predict(X_test_pca)\n",
    "\n",
    "start = time.time()\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions_pca)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "print(\"Reduced data Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Plotting the reduced data to find if they form uniform clusters\n",
    "\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('EMNIST ByClass Dataset - PCA')\n",
    "plt.colorbar(label='Class')\n",
    "plt.savefig('pca.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Plot examples of PCA compressed SVM results\n",
    "plot_examples(X_test, predictions_pca, y_test, n_rows=5, n_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0f1fb",
   "metadata": {},
   "source": [
    "# SVM with default paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a68849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVM model with default hyperparameters\n",
    "svm_model = SVC(kernel='poly', C=1.0, gamma='scale')\n",
    "\n",
    "start = time.time()\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_SVMD = svm_model.predict(X_test)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predictions_SVMD)\n",
    "precision = precision_score(y_test, predictions_SVMD, average='macro')\n",
    "recall = recall_score(y_test, predictions_SVMD, average='macro')\n",
    "confusion_mat = confusion_matrix(y_test, predictions_SVMD)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Print the evaluation metrics and confusion matrix\n",
    "print(\"Accuracy_SVMD:\", accuracy)\n",
    "print(\"Precision_SVMD:\", precision)\n",
    "print(\"Recall_SVMD:\", recall)\n",
    "print(\"Confusion Matrix_SVMD:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18047e73",
   "metadata": {},
   "source": [
    "# SVM with hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df960b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [ 0.1, 1.0, 10, 100],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "# Create an instance of the SVM model\n",
    "svm_model_param_grid = SVC(kernel='rbf')\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets for gridsearch\n",
    "X_train_Grid, X_test_Grid, y_train_Grid, y_test_Grid = train_test_split(train_images, train_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "#Create an instance of the GridSearchCV with the SVM model and parameter grid\n",
    "grid_search = GridSearchCV(svm_model_param_grid, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "start = time.time()\n",
    "# Perform grid search on the training data\n",
    "grid_search.fit(X_train_Grid, y_train_Grid)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "predictions_SVMBestparam = best_model.predict(X_test_Grid)\n",
    "\n",
    "start = time.time()\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_Grid, predictions_SVMBestparam)\n",
    "precision = precision_score(y_test_Grid, predictions_SVMBestparam, average='macro')\n",
    "recall = recall_score(y_test_Grid, predictions_SVMBestparam, average='macro')\n",
    "confusion_mat = confusion_matrix(y_test_Grid, predictions_SVMBestparam)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Print the evaluation metrics and confusion matrix\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy_SVMBestparam:\", accuracy)\n",
    "print(\"Precision_SVMBestparam:\", precision)\n",
    "print(\"Recall_SVMBestparam:\", recall)\n",
    "print(\"Confusion Matrix_SVMBestparam:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c535d5",
   "metadata": {},
   "source": [
    "# SVM with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVM model with the best hyperparameters\n",
    "svm_model = SVC(kernel='rbf', C=10, gamma='auto')\n",
    "\n",
    "start = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Make predictions\n",
    "predictions_SVMNew = svm_model.predict(X_test)\n",
    "\n",
    "start = time.time()\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predictions_SVMNew)\n",
    "precision = precision_score(y_test, predictions_SVMNew, average='macro')\n",
    "recall = recall_score(y_test, predictions_SVMNew, average='macro')\n",
    "confusion_mat = confusion_matrix(y_test, predictions_SVMNew)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Print the evaluation metrics and confusion matrix\n",
    "print(\"Accuracy_SVMNew:\", accuracy)\n",
    "print(\"Precision_SVMNew:\", precision)\n",
    "print(\"Recall_SVMNew:\", recall)\n",
    "print(\"Confusion Matrix_SVMNew:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Plot examples of best paramterized SVM\n",
    "plot_examples(X_test, predictions_SVMNew, y_test, n_rows=3, n_cols=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280bf5a",
   "metadata": {},
   "source": [
    "# SVM with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a184a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the value of the C parameter\n",
    "best_C = best_params['C']\n",
    "\n",
    "# Apply regularization by reducing C value\n",
    "regularized_C = best_C * 0.1  # Example: reduce C by 10 times\n",
    "\n",
    "# Update the C parameter in the best_params dictionary\n",
    "best_params['C'] = regularized_C\n",
    "\n",
    "# Initialize a new SVM classifier with the regularized C value\n",
    "regularized_svm = SVC(**best_params)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Fit the regularized SVM on the training data\n",
    "regularized_svm.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Make predictions on the test set using the regularized model\n",
    "predictions_Regularized = regularized_svm.predict(X_test)\n",
    "\n",
    "start = time.time()\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predictions_Regularized)\n",
    "precision = precision_score(y_test, predictions_Regularized, average='macro')\n",
    "recall = recall_score(y_test, predictions_Regularized, average='macro')\n",
    "confusion_mat = confusion_matrix(y_test, predictions_Regularized)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# Print the evaluation metrics and confusion matrix\n",
    "print(\"Regularized Parameters:\", best_params)\n",
    "print(\"Accuracy_Regularized:\", accuracy)\n",
    "print(\"Precision_Regularized:\", precision)\n",
    "print(\"Recall_Regularized:\", recall)\n",
    "print(\"Confusion Matrix_Regularized:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Plot examples of Regularized SVM\n",
    "plot_examples(X_test, predictions_Regularized, y_test, n_rows=3, n_cols=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5163116",
   "metadata": {},
   "source": [
    "# SVM Experiments with varying C and Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5160d59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define parameter grid\n",
    "C_values = np.logspace(-3, 2, num=5)  \n",
    "\n",
    "# Define kernel types\n",
    "kernels = ['rbf', 'poly']\n",
    "\n",
    "# Split your data so that you only use 50% of it for training\n",
    "sample_X_train, _, sample_y_train, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=1)\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "# Perform grid search on the training data for each kernel type and 'C' value\n",
    "for kernel in kernels:\n",
    "    for C in C_values:\n",
    "        start = time.time()\n",
    "\n",
    "        # Create an instance of the SVM model with current kernel\n",
    "        svm_model_param_grid = SVC(kernel=kernel, C=C)\n",
    "        \n",
    "        # Perform cross-validation on the training data\n",
    "        scores = cross_val_score(svm_model_param_grid, sample_X_train, sample_y_train, cv=3)\n",
    "\n",
    "        # Compute the mean accuracy and check if it's the best score so far\n",
    "        mean_score = np.mean(scores)\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_params = {'kernel': kernel, 'C': C}\n",
    "\n",
    "        # Fit the model with the 'C' parameter\n",
    "        svm_model_param_grid.fit(sample_X_train, sample_y_train)\n",
    "\n",
    "        # Make predictions on the test set using the model\n",
    "        predictions_SVMBestparam = svm_model_param_grid.predict(X_test)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, predictions_SVMBestparam)\n",
    "        precision = precision_score(y_test, predictions_SVMBestparam, average='macro')\n",
    "        recall = recall_score(y_test, predictions_SVMBestparam, average='macro')\n",
    "        confusion_mat = confusion_matrix(y_test, predictions_SVMBestparam)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Parameters: Kernel=\", kernel, \"C=\", C)\n",
    "        print(\"Mean cross-validation accuracy:\", mean_score)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"Elapsed Time:\", end - start)\n",
    "        print()\n",
    "\n",
    "print(\"Best Parameters:\", best_params, \"with highest mean cross-validation accuracy:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504944f",
   "metadata": {},
   "source": [
    "# Graph process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM RESULTS\n",
    "\n",
    "# Linear\n",
    "l_c   = [0.0010, 100.00]\n",
    "\n",
    "l_acc = [0.7264, 0.7264]\n",
    "l_pre = [0.5819, 0.5819]\n",
    "l_rec = [0.5627, 0.5627]\n",
    "l_tim = [16.308, 16.308] # in mins\n",
    "\n",
    "# non-linear\n",
    "c     = [0.0010, 0.0178, 0.3162, 5.6234, 100.00]\n",
    "\n",
    "# rbf\n",
    "r_acc = [0.0547, 0.5330, 0.7315, 0.7877, 0.7774]\n",
    "r_pre = [0.0078, 0.2271, 0.5956, 0.6843, 0.6745]\n",
    "r_rec = [0.0162, 0.2063, 0.4716, 0.5996, 0.6010]\n",
    "r_tim = [83.476, 371.14, 32.134, 25.899, 30.315] # in mins\n",
    "     \n",
    "# poly\n",
    "p_acc = [0.0551, 0.2600, 0.6809, 0.7869, 0.7811]\n",
    "p_pre = [0.0474, 0.3639, 0.5755, 0.6781, 0.6726]\n",
    "p_rec = [0.0175, 0.1091, 0.3982, 0.5922, 0.6062]\n",
    "p_tim = [148.38, 64.932, 45.097, 30.960, 29.848] # in mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM GRAPHS\n",
    "\n",
    "# Produce Line Plots\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 7.5))\n",
    "\n",
    "# ACCURACY\n",
    "axs[0, 0].plot(c, r_acc, color='cyan')\n",
    "axs[0, 0].plot(c, p_acc, color='chartreuse')\n",
    "axs[0, 0].plot(l_c, l_acc, color='orange', linestyle='dashed')\n",
    "axs[0, 0].legend(('RBF','Polynomial','Linear'),loc='upper left')\n",
    "axs[0, 0].set_title('SVM Accuracy')\n",
    "#axs[0, 0].set_xlabel('C Value')\n",
    "axs[0, 0].set_ylabel('Accuracy Score')\n",
    "axs[0, 0].set_xscale('log')\n",
    "\n",
    "# PRECISION\n",
    "axs[0, 1].plot(c, r_pre, color='cyan')\n",
    "axs[0, 1].plot(c, p_pre, color='chartreuse')\n",
    "axs[0, 1].plot(l_c, l_pre, color='orange', linestyle='dashed')\n",
    "#axs[0, 1].legend(('RBF','Polynomial','Linear'),loc='upper left')\n",
    "axs[0, 1].set_title('SVM Precision')\n",
    "#axs[0, 1].set_xlabel('C Value')\n",
    "axs[0, 1].set_ylabel('Precision Score')\n",
    "axs[0, 1].set_xscale('log')\n",
    "\n",
    "# RECALL\n",
    "axs[1, 0].plot(c, r_rec, color='cyan')\n",
    "axs[1, 0].plot(c, p_rec, color='chartreuse')\n",
    "axs[1, 0].plot(l_c, l_rec, color='orange', linestyle='dashed')\n",
    "#axs[1, 0].legend(('RBF','Polynomial','Linear'),loc='upper left')\n",
    "axs[1, 0].set_title('SVM Recall')\n",
    "axs[1, 0].set_xlabel('C Value')\n",
    "axs[1, 0].set_ylabel('Recall Score')\n",
    "axs[1, 0].set_xscale('log')\n",
    "\n",
    "# COMPUTATIONAL TIME\n",
    "axs[1, 1].plot(c, r_tim, color='cyan')\n",
    "axs[1, 1].plot(c, p_tim, color='chartreuse')\n",
    "axs[1, 1].plot(l_c, l_tim, color='orange', linestyle='dashed')\n",
    "#axs[1, 1].legend(('RBF','Polynomial','Linear'),loc='upper left')\n",
    "axs[1, 1].set_title('SVM Computational Time')\n",
    "axs[1, 1].set_xlabel('C Value')\n",
    "axs[1, 1].set_ylabel('Time Taken [mins]')\n",
    "axs[1, 1].set_xscale('log')\n",
    "\n",
    "#plt.savefig('svm_experiment_singlelegend.pdf', bbox_inches='tight', pad_inches=0.3, dpi = 500) #save plot as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN RESULTS\n",
    "\n",
    "units = [128.00, 256.00, 384.00, 512.00]\n",
    "\n",
    "# LR 1e-2\n",
    "e2acc = [0.8477, 0.8506, 0.8467, 0.8453]\n",
    "e2pre = [0.8043, 0.8134, 0.7905, 0.7943]\n",
    "e2rec = [0.6988, 0.7079, 0.7131, 0.7128]\n",
    "e2tim = [15.330, 16.511, 16.525, 18.301] # in mins\n",
    "     \n",
    "# LR 1e-3\n",
    "e3acc = [0.8526, 0.8573, 0.8541, 0.8522]\n",
    "e3pre = [0.7867, 0.7893, 0.7530, 0.7637]\n",
    "e3rec = [0.7073, 0.7183, 0.7165, 0.7207]\n",
    "e3tim = [15.259, 15.162, 16.406, 18.554] # in mins\n",
    "    \n",
    "# LR 1e-4\n",
    "e4acc = [0.8430, 0.8464, 0.8433, 0.8498]\n",
    "e4pre = [0.7861, 0.7865, 0.7891, 0.7788]\n",
    "e4rec = [0.6870, 0.6944, 0.7015, 0.6996]\n",
    "e4tim = [15.029, 15.188, 17.574, 17.782] # in mins\n",
    "    \n",
    "# LR 1e-5\n",
    "e5acc = [0.7347, 0.7670, 0.7773, 0.7899]\n",
    "e5pre = [0.7163, 0.6845, 0.6900, 0.7265]\n",
    "e5rec = [0.4756, 0.5549, 0.5786, 0.5978]\n",
    "e5tim = [14.759, 16.532, 18.571, 18.290] # in mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f23e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN GRAPHS\n",
    "\n",
    "# Produce Line Plots\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 7.5))\n",
    "\n",
    "# ACCURACY\n",
    "axs[0, 0].plot(units, e2acc, color='cyan')\n",
    "axs[0, 0].plot(units, e3acc, color='chartreuse')\n",
    "axs[0, 0].plot(units, e4acc, color='orange')\n",
    "axs[0, 0].plot(units, e5acc, color='violet')\n",
    "axs[0, 0].legend(('Learning rate: 1e-02','Learning rate: 1e-03','Learning rate: 1e-04','Learning rate: 1e-05'),bbox_to_anchor=(0.39,0.63),loc='center right')\n",
    "axs[0, 0].set_title('CNN Accuracy')\n",
    "#axs[0, 0].set_xlabel('Number of Dense Units')\n",
    "axs[0, 0].set_ylabel('Accuracy Score')\n",
    "#axs[0, 0].set_xscale('log')\n",
    "\n",
    "# PRECISION\n",
    "axs[0, 1].plot(units, e2pre, color='cyan')\n",
    "axs[0, 1].plot(units, e3pre, color='chartreuse')\n",
    "axs[0, 1].plot(units, e4pre, color='orange')\n",
    "axs[0, 1].plot(units, e5pre, color='violet')\n",
    "#axs[0, 1].legend(('Learning rate: 1e-02','Learning rate: 1e-03','Learning rate: 1e-04','Learning rate: 1e-05'),bbox_to_anchor=(0.39,0.63),loc='center right')\n",
    "axs[0, 1].set_title('CNN Precision')\n",
    "#axs[0, 1].set_xlabel('Number of Dense Units')\n",
    "axs[0, 1].set_ylabel('Precision Score')\n",
    "#axs[0, 1].set_xscale('log')\n",
    "\n",
    "# RECALL\n",
    "axs[1, 0].plot(units, e2rec, color='cyan')\n",
    "axs[1, 0].plot(units, e3rec, color='chartreuse')\n",
    "axs[1, 0].plot(units, e4rec, color='orange')\n",
    "axs[1, 0].plot(units, e5rec, color='violet')\n",
    "#axs[1, 0].legend(('Learning rate: 1e-02','Learning rate: 1e-03','Learning rate: 1e-04','Learning rate: 1e-05'),bbox_to_anchor=(0.39,0.63),loc='center right')\n",
    "axs[1, 0].set_title('CNN Recall')\n",
    "axs[1, 0].set_xlabel('Number of Dense Units')\n",
    "axs[1, 0].set_ylabel('Recall Score')\n",
    "#axs[1, 0].set_xscale('log')\n",
    "\n",
    "# COMPUTATIONAL TIME\n",
    "axs[1, 1].plot(units, e2tim, color='cyan')\n",
    "axs[1, 1].plot(units, e3tim, color='chartreuse')\n",
    "axs[1, 1].plot(units, e4tim, color='orange')\n",
    "axs[1, 1].plot(units, e5tim, color='violet')\n",
    "#axs[1, 1].legend(('Learning rate: 1e-02','Learning rate: 1e-03','Learning rate: 1e-04','Learning rate: 1e-05'),bbox_to_anchor=(0.39,0.63),loc='center right')\n",
    "axs[1, 1].set_title('CNN Computational Time')\n",
    "axs[1, 1].set_xlabel('Number of Dense Units')\n",
    "axs[1, 1].set_ylabel('Time Taken [mins]')\n",
    "#axs[1, 0].set_xscale('log')\n",
    "\n",
    "#plt.savefig('cnn_experiment_singlelegend.pdf', bbox_inches='tight', pad_inches=0.3, dpi = 500) #save plot as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb48fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP RESULTS\n",
    "\n",
    "n_neu = [50.000, 66.000, 83.000, 100.00, 116.00, 133.00, 150.00, 166.00, 183.00, 200.00]\n",
    "\n",
    "# RELU\n",
    "r_acc = [0.7868, 0.7922, 0.8030, 0.8025, 0.8086, 0.8125, 0.8125, 0.8147, 0.8154, 0.8126]\n",
    "r_pre = [0.6636, 0.6652, 0.6812, 0.6863, 0.6939, 0.6982, 0.7013, 0.6930, 0.6940, 0.7021]\n",
    "r_rec = [0.6185, 0.6344, 0.6429, 0.6486, 0.6528, 0.6641, 0.6544, 0.6728, 0.6648, 0.6722]\n",
    "r_tim = [0.2138, 0.2233, 0.2327, 0.2923, 0.3003, 0.4704, 0.5358, 0.4253, 0.4250, 0.4445] # in mins\n",
    "\n",
    "# SIGMOID\n",
    "s_acc = [0.7568, 0.7700, 0.7840, 0.7901, 0.7984, 0.8029, 0.8053, 0.8106, 0.8093, 0.8116]\n",
    "s_pre = [0.6096, 0.6250, 0.6600, 0.6758, 0.6876, 0.6874, 0.6887, 0.7030, 0.6879, 0.6993]\n",
    "s_rec = [0.5539, 0.5751, 0.5995, 0.6182, 0.6297, 0.6400, 0.6351, 0.6487, 0.6430, 0.6541]\n",
    "s_tim = [0.2808, 0.2752, 0.2767, 0.3148, 0.3440, 0.3292, 0.3756, 0.3317, 0.3293, 0.5226] # in mins\n",
    "\n",
    "# TANH\n",
    "t_acc = [0.7815, 0.7937, 0.7999, 0.8033, 0.8076, 0.8150, 0.8069, 0.8122, 0.8155, 0.8084]\n",
    "t_pre = [0.6459, 0.6639, 0.6921, 0.6831, 0.6873, 0.7001, 0.6904, 0.6900, 0.7004, 0.7131]\n",
    "t_rec = [0.6050, 0.6251, 0.6362, 0.6559, 0.6567, 0.6618, 0.6547, 0.6677, 0.6664, 0.6643]\n",
    "t_tim = [0.2080, 0.2269, 0.2690, 0.2566, 0.2838, 0.2688, 0.2873, 0.2582, 0.4052, 0.4425] # in mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP GRAPHS\n",
    "\n",
    "# Produce Line Plots\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 7.5))\n",
    "\n",
    "# ACCURACY\n",
    "axs[0, 0].plot(n_neu, r_acc, color='cyan')\n",
    "axs[0, 0].plot(n_neu, s_acc, color='chartreuse')\n",
    "axs[0, 0].plot(n_neu, t_acc, color='orange')\n",
    "axs[0, 0].legend(('ReLU','Sigmoid','Tanh'),loc='upper left')\n",
    "axs[0, 0].set_title('MLP Accuracy')\n",
    "#axs[0, 0].set_xlabel('Number of Hidden Neurons')\n",
    "axs[0, 0].set_ylabel('Accuracy Score')\n",
    "\n",
    "# PRECISION\n",
    "axs[0, 1].plot(n_neu, r_pre, color='cyan')\n",
    "axs[0, 1].plot(n_neu, s_pre, color='chartreuse')\n",
    "axs[0, 1].plot(n_neu, t_pre, color='orange')\n",
    "#axs[0, 1].legend(('ReLU','Sigmoid','Tanh'),loc='upper left')\n",
    "axs[0, 1].set_title('MLP Precision')\n",
    "#axs[0, 1].set_xlabel('Number of Hidden Neurons')\n",
    "axs[0, 1].set_ylabel('Precision Score')\n",
    "\n",
    "# RECALL\n",
    "axs[1, 0].plot(n_neu, r_rec, color='cyan')\n",
    "axs[1, 0].plot(n_neu, s_rec, color='chartreuse')\n",
    "axs[1, 0].plot(n_neu, t_rec, color='orange')\n",
    "#axs[1, 0].legend(('ReLU','Sigmoid','Tanh'),loc='upper left')\n",
    "axs[1, 0].set_title('MLP Recall')\n",
    "axs[1, 0].set_xlabel('Number of Hidden Neurons')\n",
    "axs[1, 0].set_ylabel('Recall Score')\n",
    "\n",
    "# COMPUTATIONAL TIME\n",
    "axs[1, 1].plot(n_neu, r_tim, color='cyan')\n",
    "axs[1, 1].plot(n_neu, s_tim, color='chartreuse')\n",
    "axs[1, 1].plot(n_neu, t_tim, color='orange')\n",
    "#axs[1, 1].legend(('ReLU','Sigmoid','Tanh'),loc='upper left')\n",
    "axs[1, 1].set_title('MLP Computational Time')\n",
    "axs[1, 1].set_xlabel('Number of Hidden Neurons')\n",
    "axs[1, 1].set_ylabel('Time Taken [mins]')\n",
    "\n",
    "#plt.savefig('mlp_experiment_singlelegend.pdf', bbox_inches='tight', pad_inches=0.3, dpi = 500) #save plot as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall best models\n",
    "\n",
    "#      acc.    pre.    rec.    tim.   # time is % of 30 mins\n",
    "svm = [0.8042, 0.7042, 0.6340, 0.7657]\n",
    "cnn = [0.8522, 0.7637, 0.7207, 0.6185]\n",
    "mlp = [0.8126, 0.7021, 0.6722, 0.0148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ee190",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = (\"Accuracy Score\", \"Precision Score\", \"Recall Score\", \"Time Taken [30mins]\")\n",
    "scores = {\n",
    "    'Support Vector Machine': (0.804, 0.704, 0.634, 0.766),\n",
    "    'Convolutional Neura': (0.852, 0.764, 0.721, 0.619),\n",
    "    'MLP': (0.813, 0.702, 0.672, 0.015),\n",
    "}\n",
    "\n",
    "x = np.arange(len(measures))  # the label locations\n",
    "width = 0.18  # the width of the bars\n",
    "multiplier = 0\n",
    "colors = ['cyan','chartreuse','orange']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for attribute, measurement in scores.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute, color=colors[multiplier])\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_title('Comparison of Evaluation Metrics for All Models')\n",
    "ax.set_xticks(x + width, measures)\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "\n",
    "#plt.savefig('best_models.pdf', bbox_inches='tight', pad_inches=0.3, dpi = 500) #save plot as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00ef78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
